{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KYQssL1p4qjJ",
        "aUkZxlSxMMRL",
        "zXjS9Va4jB58",
        "scKkoMwhs_WI",
        "HLaCLraMoVoa",
        "h5NcGuWGvLKB",
        "6MjNN_C-_dUj",
        "Gtt1K9VWKVcr",
        "X9HlgRzfGk4u",
        "GUUx0X1UDP6-",
        "xqu7G5ITCD-7",
        "nZxHW-15M126"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOh31qUuE/GYiQ7FzouDVm9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Pytorch/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlSBzKQekHBL",
        "outputId": "8a9161d8-28ad-49ad-8a95-677fd8c3a58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k4nLdvWzUVOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ac3221-a858-4607-cc4b-a02a85e7b6aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Device"
      ],
      "metadata": {
        "id": "B3o7FS8UMI-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "9HwpVdzCGFc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01cd93b-8c75-461d-ad7f-eeee57b9e768"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "-NvRrtYVV7Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "9r7TYDYPV_OO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(root='/content/data', train=True, download=True, transform=ToTensor())\n",
        "test_dataset = MNIST(root='/content/data', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "id": "PP2vmyzRWrEg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting features and labels for Training Data\n",
        "X_train=train_dataset.data\n",
        "y_train=train_dataset.targets\n",
        "\n",
        "# Extracting features and labels for Test Data\n",
        "X_test=test_dataset.data\n",
        "y_test=test_dataset.targets"
      ],
      "metadata": {
        "id": "UJ1FVl2_WyRw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZXST_Q3340p",
        "outputId": "e1bd3d4e-9c06-4046-ed3d-30fac9bc5bab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Valid Split"
      ],
      "metadata": {
        "id": "KYQssL1p4qjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttv_split(data,train_split,test_split,seed=None):\n",
        "  if train_split+test_split>100:\n",
        "    raise Exception(\"Train, Test Split Should not sum to more than 100%\")\n",
        "  train, test, val  = np.split(data.sample(frac=1,random_state=seed), [int((train_split/100)*len(data)), int(((train_split/100)+(test_split/100))*len(data))])\n",
        "  return train, test, val\n",
        "\n",
        "def train_test_valid_split(features,labels,seed,train_split,test_split):\n",
        "  X_train, X_test, X_val=ttv_split(data=features,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  y_train, y_test, y_val=ttv_split(data=labels,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  return (X_train,y_train),(X_test,y_test),(X_val,y_val)"
      ],
      "metadata": {
        "id": "At784OsbqUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test),(X_val,y_val)=train_test_valid_split(features=X,\n",
        "                                                                       labels=y,\n",
        "                                                                       seed=40,\n",
        "                                                                       train_split=60,\n",
        "                                                                       test_split=20)\n",
        "X_train"
      ],
      "metadata": {
        "id": "H-zPGrg3jnAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Dataset"
      ],
      "metadata": {
        "id": "aUkZxlSxMMRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "def MyDataset(features,labels,transform=None):\n",
        "  def __init__(self):\n",
        "    # self.dataset=dataset\n",
        "    self.features=self.dataset.drop(-1)\n",
        "    self.labels=self.dataset\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "    y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
        "    return (image,y_label)\n",
        "# train_loader=DataLoader(dataset=dataset,batch_size=16,shuffle=True,num_worker=4,pin_memory=False)"
      ],
      "metadata": {
        "id": "rXycNwmg6DpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=MyDataset(X_train,y_train)\n",
        "test_set=MyDataset(X_test,y_test)\n",
        "val_set=MyDataset(X_val,y_val)"
      ],
      "metadata": {
        "id": "NtIoyGD_OMMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "cVCbVGWyc6Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "test_loader=DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
        "# val_loader=DataLoader(val_set, batch_size=128,shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "J8yinvOM45rX"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Model"
      ],
      "metadata": {
        "id": "mx9yC9iqORKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1=torch.nn.Conv2d(1,32,kernel_size=3,padding=1)\n",
        "    self.conv2=torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool1=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv3=torch.nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "    self.conv4=torch.nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool2=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv5=torch.nn.Conv2d(128,256,kernel_size=3,padding=1)\n",
        "    self.conv6=torch.nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool3=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.fc1=torch.nn.Linear(64*14*14,1024)\n",
        "    self.fc2=torch.nn.Linear(1024,512)\n",
        "    self.fc32=torch.nn.Linear(512,10)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.maxpool1(x)\n",
        "\n",
        "    # x=self.conv3(x)\n",
        "    # x=F.relu(x)\n",
        "    # x=self.conv4(x)\n",
        "    # x=F.relu(x)\n",
        "    # x=self.maxpool2(x)\n",
        "\n",
        "    # x=self.conv5(x)\n",
        "    # x=F.relu(x)\n",
        "    # x=self.conv6(x)\n",
        "    # x=F.relu(x)\n",
        "    # x=self.maxpool3(x)\n",
        "\n",
        "    x=x.view(x.size(0),64*14*14)\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    x=F.relu(x)\n",
        "    # x=F.log_softmax(x,dim=-1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "8IhvIK3gpWkR"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model=MyModel()\n",
        "model.to(device)\n",
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "id": "mmrjvZPdKCOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5543d94b-9d35-4fe7-b076-96975d7a41a1"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Linear-4                 [-1, 1024]      12,846,080\n",
            "            Linear-5                  [-1, 512]         524,800\n",
            "================================================================\n",
            "Total params: 13,389,696\n",
            "Trainable params: 13,389,696\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.68\n",
            "Params size (MB): 51.08\n",
            "Estimated Total Size (MB): 51.76\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, Training and testing Loop Setup\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "epochs=100\n",
        "learning_rate=1e-3\n",
        "optimizer=torch.optim.RMSprop(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "\n",
        "test_loss_history=[]\n",
        "test_accuracy_history=[]\n",
        "train_loss_history=[]\n",
        "train_accuracy_history=[]"
      ],
      "metadata": {
        "id": "yQA8f7fHK1f6"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Testing and Fit Loops and Functions"
      ],
      "metadata": {
        "id": "fZu2iEFJo9y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function and Loop\n",
        "def train(train_loader,model,loss_function,optimizer):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "  train_accuracy=0\n",
        "\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "\n",
        "    train_loss+=loss.item()\n",
        "    _, pred_indices= torch.max(predictions.data, 1)\n",
        "    train_accuracy+=(pred_indices == labels).sum().item()/len(labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  num_batches=len(train_loader)\n",
        "  train_loss_per_epoch=train_loss/num_batches\n",
        "  train_loss_history.append(train_loss_per_epoch)\n",
        "\n",
        "  train_accuracy_per_epoch=train_accuracy/num_batches\n",
        "  train_accuracy_history.append(train_accuracy_per_epoch)\n",
        "  print(f\"Train Loss: {train_loss_per_epoch:.4f}, Train Accuracy: {train_accuracy_per_epoch:.4f}\")"
      ],
      "metadata": {
        "id": "znCJWC7khMvu"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Function and Loop\n",
        "def test(test_loader,model,loss_function):\n",
        "  model.eval()\n",
        "  test_loss=0\n",
        "  test_accuracy=0\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for features, labels in test_loader:\n",
        "      features, labels = features.to(device), labels.to(device)\n",
        "      predictions=model(features)\n",
        "      loss=loss_function(predictions,labels)\n",
        "\n",
        "      test_loss+=loss.item()\n",
        "      _, pred_indices= torch.max(predictions.data, 1)\n",
        "      test_accuracy+=(pred_indices == labels).sum().item()/len(labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.requires_grad = True\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    num_batches=len(test_loader)\n",
        "    test_loss_per_epoch=test_loss/num_batches\n",
        "    test_loss_history.append(test_loss_per_epoch)\n",
        "\n",
        "    test_accuracy_per_epoch=test_accuracy/num_batches\n",
        "    test_accuracy_history.append(test_accuracy_per_epoch)\n",
        "\n",
        "    print(f\"Test Loss: {test_loss_per_epoch:.4f}, Test Accuracy: {test_accuracy_per_epoch:.4f}\")"
      ],
      "metadata": {
        "id": "Tbgy2PisjGpV"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Function\n",
        "for epoch in range(100):\n",
        "  print(\"epoch:\",epoch)\n",
        "  train(train_loader,model,loss_function,optimizer)\n",
        "  test(test_loader,model,loss_function)\n",
        "  print(\"---------------------------------------------------------------\")\n",
        "  print(\"---------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "jysHzuHij1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## History Plots of Accuracy and Loss"
      ],
      "metadata": {
        "id": "zXjS9Va4jB58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "ax.plot(train_loss_history, label='Train Loss')\n",
        "ax.plot(test_loss_history, label='Test Loss')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_title('Train and Test Loss')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S4OfyFcxjIlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "ax.plot(train_accuracy_history, label='Train Accuracy')\n",
        "ax.plot(test_accuracy_history, label='Test Accuracy')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Train and Test Accuracy')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XHIHkdc5kUet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "scKkoMwhs_WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "  images, labels=images.to(device), labels.to(device)\n",
        "  sample=images[0].unsqueeze(0)\n",
        "  outputs=model(sample)\n",
        "  _, predictions= torch.max(outputs.data, 1)\n",
        "  print(\"Label: \",labels[0].item())\n",
        "  print(\"Prediction: \",predictions.item())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3YOy0HTujgy",
        "outputId": "9c9940d2-70ab-45ca-aef6-a6bf139c733b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  6\n",
            "Prediction:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Like Style for Training Loss and Accuracy"
      ],
      "metadata": {
        "id": "HLaCLraMoVoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Epoch {epoch+1}/{num_epochs} - Batch {batch_idx+1}/{len(dataloader)} - Loss: {loss.item()}\\r\", end='')"
      ],
      "metadata": {
        "id": "vuEjD4p7mOTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for i in range(10):\n",
        "  print(f\"{i}\",end='')\n",
        "  time.sleep(0.7)\n",
        "  print(\"\\r\",end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgOlDkNjmQVG",
        "outputId": "b201cfdf-13b0-4b1e-c9d0-e1a5e18975bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model"
      ],
      "metadata": {
        "id": "h5NcGuWGvLKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model.pt')"
      ],
      "metadata": {
        "id": "MGt3MK2jvNCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model"
      ],
      "metadata": {
        "id": "6MjNN_C-_dUj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUP2aoWN_fzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DUMPSTER\n"
      ],
      "metadata": {
        "id": "QgpYnR5AMO3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imp Random"
      ],
      "metadata": {
        "id": "Gtt1K9VWKVcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # def forward(self,x):\n",
        "    #   xb=xb.reshape(-1,784)\n",
        "    #   out=self.linear(xb)\n",
        "    #   return out\n",
        "\n",
        "    # def training_step(self,batch):\n",
        "    #   images,labels=batch\n",
        "    #   outputs=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   return loss\n",
        "\n",
        "    # def validation_step(self,batch):\n",
        "    #   images, labels=batch\n",
        "    #   out=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   acc=accuracy(outputs,labels)\n",
        "    #   return {'val_loss':loss,'val_acc':acc}\n",
        "\n",
        "\n",
        "# for parameter in model.parameters():\n",
        "# print(parameter.shape\n",
        "# model.linear1\n",
        "# model.linear2\n",
        "# model.activation\n",
        "# model.softmax\n"
      ],
      "metadata": {
        "id": "VSeicov0I7oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.linear1"
      ],
      "metadata": {
        "id": "_WSjvHwEHmat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[1,2,3,4,5,6,7,8,9,10]\n",
        "x_square=[sample**2 for sample in x]\n",
        "x_square"
      ],
      "metadata": {
        "id": "bbUjbeD4qcVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "def evaluate(model,val_loader):\n",
        "  outputs=[models.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "UoAdadqtpXHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Val, Test Loop\n",
        "for epoch in range(100):\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Ac0egWHXfux9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Practices"
      ],
      "metadata": {
        "id": "X9HlgRzfGk4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=O2wJ3tkc-TU\n",
        "# https://www.youtube.com/watch?v=2AhiHV7QGVk"
      ],
      "metadata": {
        "id": "HMEkLd_wGofC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning and HyperParameter Training"
      ],
      "metadata": {
        "id": "GUUx0X1UDP6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=qaDe0qQZ5AQ"
      ],
      "metadata": {
        "id": "ZfF1NTTCDPoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(image).item()"
      ],
      "metadata": {
        "id": "h0LdMB2D4SYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Activation Function, Loss Function, Optimzer:"
      ],
      "metadata": {
        "id": "xqu7G5ITCD-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Optimizer:\n",
        "# https://www.youtube.com/watch?v=zvp8K4iX2Cs&pp=ygUUY3VzdG9tIG1vZGVsIHB5dG9yY2g%3D"
      ],
      "metadata": {
        "id": "nfGfYIoJAS7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk []\n",
        "# https://www.youtube.com/watch?v=OIenNRt2bjg []\n",
        "# https://www.youtube.com/watch?v=H69j69FFMV0 [Dataset Spli First, then Data Loader]\n",
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk"
      ],
      "metadata": {
        "id": "PGAZvl4nGMY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self): #Initializing the MyModel Class\n",
        "    super().__init__() #Calling The Parent Class\n"
      ],
      "metadata": {
        "id": "tWrI3rZxkaFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Dumpster"
      ],
      "metadata": {
        "id": "nZxHW-15M126"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.tensor([1,2,3,4,5])\n",
        "print(data)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "6ZDEw6IqAyWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor Gradients\n",
        "x=torch.tensor(3.)\n",
        "w=torch.tensor(4.,requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True)"
      ],
      "metadata": {
        "id": "TQLDc9scBxw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the value of y\n",
        "y=x*w+b\n",
        "y"
      ],
      "metadata": {
        "id": "fzcRkKifCOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.full((3,3),101)\n",
        "data"
      ],
      "metadata": {
        "id": "OMGdlZ8QDTRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converts numpy array to tensor\n",
        "import numpy as np\n",
        "x=np.ones((3,2))\n",
        "y=torch.from_numpy(x)\n",
        "x.dtype, y.dtype\n",
        "# Internally both are the same"
      ],
      "metadata": {
        "id": "Soe9NU87E3Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Tensor to numpy\n",
        "x=torch.ones((3,2))\n",
        "y=x.numpy()\n",
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "id": "YOznszjsFNsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of element in a tensor\n",
        "x.numel()"
      ],
      "metadata": {
        "id": "NBNt8DIoJceo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if gradient +ve:\n",
        "#   increasing the weight value increases loss\n",
        "#   decreasing the weight value decreases loss\n",
        "\n",
        "# if gradient -ve:\n",
        "#   increasing the weight value decreases loss\n",
        "#   decreasing the weight value increases loss"
      ],
      "metadata": {
        "id": "0b1GFoafCqTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value=value-stepsize\n",
        "value=value-lr*slope\n",
        "value=value-lr*gradient\n",
        "value=value-lr*derivative"
      ],
      "metadata": {
        "id": "htkm5zgMDyH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "loss_func=F.mse_loss\n",
        "loss=loss_func(model(input),labels)"
      ],
      "metadata": {
        "id": "Et0a1zaQPhvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers perform the gradient descent, that is they adjust the weights and biases of parameters\n",
        "optim=torch.optim.SGD(model.parameters,lr=1e-5)"
      ],
      "metadata": {
        "id": "UgnPnhWxSox2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def fit(num_epochs,model,loss_func,optim,train):\n",
        "for epoch in range(num_epochs):\n",
        "  for x,y in train:\n",
        "    prediction=model(x)\n",
        "    loss=loss_func(prediction,y)\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer performs gradient descent and updates the Weights and Biases of Features/Parameters\n",
        "    optim.step()\n",
        "\n",
        "    # Reset the gradients for next epoch\n",
        "    optim.zero_grad()"
      ],
      "metadata": {
        "id": "8M25LGBgSbyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "uOwh4_fIXCMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms are used for handling image data one such usage is ToTensor() function"
      ],
      "metadata": {
        "id": "KO0-5LPoYd-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random split in Pytorch\n",
        "from torch.utils.data import random_split\n",
        "train_ds, val_ds - random_split(dataset, [50000, 10000])\n",
        "len (train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "xBCk0aqjZsUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_data,batch_size,shuffle=True) #Shuffle=True so that with each epoch the batches are not send in the same order, this helps to generalize model better\n",
        "val_loader=DataLoader(val_data,batch_size)"
      ],
      "metadata": {
        "id": "qtDe5F3IaiPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "images.reshape(128,784)\n",
        "model.parameters()\n",
        "model.linear.weights.shape\n",
        "model.linear.bias.shape"
      ],
      "metadata": {
        "id": "p_o82WFvbj8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "numbers = np.arange(1, 21)\n",
        "labels = np.random.randint(0, 2, size=20)\n",
        "df = pd.DataFrame({'Numbers': numbers, 'Labels': labels})\n",
        "df"
      ],
      "metadata": {
        "id": "qKGMpG2ri1Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1:]"
      ],
      "metadata": {
        "id": "ZnORWEf65iLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "predicted_labels = torch.tensor([1, 2, 3, 4])\n",
        "  # Example predicted labels\n",
        "ground_truth_labels = torch.tensor([1, 2, 4, 4])\n",
        "  # Example ground truth labels\n",
        "\n",
        "correct = (predicted_labels == ground_truth_labels).sum().item()\n",
        "total = len(predicted_labels)\n",
        "train_accuracy_per_epoch = correct / total\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "train_accuracy_per_epoch*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-qdnCInRilU",
        "outputId": "546e6cfb-1db4-410e-f27a-a6d78648dfed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}