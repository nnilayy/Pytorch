{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B3o7FS8UMI-p",
        "-NvRrtYVV7Wy",
        "KYQssL1p4qjJ",
        "aUkZxlSxMMRL",
        "HLaCLraMoVoa",
        "h5NcGuWGvLKB",
        "6MjNN_C-_dUj",
        "QgpYnR5AMO3n",
        "Gtt1K9VWKVcr",
        "X9HlgRzfGk4u",
        "GUUx0X1UDP6-",
        "xqu7G5ITCD-7",
        "nZxHW-15M126"
      ],
      "authorship_tag": "ABX9TyMIGtBMi/FCml1M1z8TLili",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Pytorch/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlSBzKQekHBL",
        "outputId": "32c03a40-b84b-4425-ca42-585b7ab8644c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k4nLdvWzUVOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770d78a2-4598-4e91-9af9-b5e734d24d5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Device"
      ],
      "metadata": {
        "id": "B3o7FS8UMI-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "9HwpVdzCGFc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177929d0-7477-4ddd-e730-180c7b7f1e4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "-NvRrtYVV7Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "9r7TYDYPV_OO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(root='/content/data', train=True, download=True, transform=ToTensor())\n",
        "test_dataset = MNIST(root='/content/data', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "id": "PP2vmyzRWrEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting features and labels for Training Data\n",
        "X_train=train_dataset.data\n",
        "y_train=train_dataset.targets\n",
        "\n",
        "# Extracting features and labels for Test Data\n",
        "X_test=test_dataset.data\n",
        "y_test=test_dataset.targets"
      ],
      "metadata": {
        "id": "UJ1FVl2_WyRw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZXST_Q3340p",
        "outputId": "cdaeac9f-db72-47c7-83a8-944f4871fa34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Valid Split"
      ],
      "metadata": {
        "id": "KYQssL1p4qjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttv_split(data,train_split,test_split,seed=None):\n",
        "  if train_split+test_split>100:\n",
        "    raise Exception(\"Train, Test Split Should not sum to more than 100%\")\n",
        "  train, test, val  = np.split(data.sample(frac=1,random_state=seed), [int((train_split/100)*len(data)), int(((train_split/100)+(test_split/100))*len(data))])\n",
        "  return train, test, val\n",
        "\n",
        "def train_test_valid_split(features,labels,seed,train_split,test_split):\n",
        "  X_train, X_test, X_val=ttv_split(data=features,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  y_train, y_test, y_val=ttv_split(data=labels,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  return (X_train,y_train),(X_test,y_test),(X_val,y_val)"
      ],
      "metadata": {
        "id": "At784OsbqUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test),(X_val,y_val)=train_test_valid_split(features=X,\n",
        "                                                                       labels=y,\n",
        "                                                                       seed=40,\n",
        "                                                                       train_split=60,\n",
        "                                                                       test_split=20)\n",
        "X_train"
      ],
      "metadata": {
        "id": "H-zPGrg3jnAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Dataset"
      ],
      "metadata": {
        "id": "aUkZxlSxMMRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "def MyDataset(features,labels,transform=None):\n",
        "  def __init__(self):\n",
        "    # self.dataset=dataset\n",
        "    self.features=self.dataset.drop(-1)\n",
        "    self.labels=self.dataset\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "    y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
        "    return (image,y_label)\n",
        "# train_loader=DataLoader(dataset=dataset,batch_size=16,shuffle=True,num_worker=4,pin_memory=False)"
      ],
      "metadata": {
        "id": "rXycNwmg6DpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=MyDataset(X_train,y_train)\n",
        "test_set=MyDataset(X_test,y_test)\n",
        "val_set=MyDataset(X_val,y_val)"
      ],
      "metadata": {
        "id": "NtIoyGD_OMMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "cVCbVGWyc6Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "test_loader=DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
        "# val_loader=DataLoader(val_set, batch_size=128,shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "J8yinvOM45rX"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Model"
      ],
      "metadata": {
        "id": "mx9yC9iqORKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1=torch.nn.Conv2d(1,32,kernel_size=3,padding=1)\n",
        "    self.conv2=torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool1=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv3=torch.nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "    self.conv4=torch.nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool2=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv5=torch.nn.Conv2d(128,256,kernel_size=3,padding=1)\n",
        "    self.conv6=torch.nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool3=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.fc1=torch.nn.Linear(256*3*3,1024)\n",
        "    self.fc2=torch.nn.Linear(1024,512)\n",
        "    self.fc32=torch.nn.Linear(512,10)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.maxpool1(x)\n",
        "\n",
        "    x=self.conv3(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv4(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.maxpool2(x)\n",
        "\n",
        "    x=self.conv5(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv6(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.maxpool3(x)\n",
        "\n",
        "    x=x.view(x.size(0),256*3*3)\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    x=F.relu(x)\n",
        "    x=F.log_softmax(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "8IhvIK3gpWkR"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model=MyModel()\n",
        "model.to(device)\n",
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "id": "mmrjvZPdKCOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdbcdec7-e594-4244-cecd-68189b30320d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 128, 14, 14]         147,584\n",
            "         MaxPool2d-6            [-1, 128, 7, 7]               0\n",
            "            Conv2d-7            [-1, 256, 7, 7]         295,168\n",
            "            Conv2d-8            [-1, 256, 7, 7]         590,080\n",
            "         MaxPool2d-9            [-1, 256, 3, 3]               0\n",
            "================================================================\n",
            "Total params: 1,125,504\n",
            "Trainable params: 1,125,504\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.31\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 5.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, Training and testing Loop Setup\n",
        "import torch.nn.functional as F\n",
        "epochs=100\n",
        "learning_rate=1e-4\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "yQA8f7fHK1f6"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Testing and Fit Loops and Functions"
      ],
      "metadata": {
        "id": "fZu2iEFJo9y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function and Loop\n",
        "def train(train_loader,model,loss_function,optimizer):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "    train_loss+=loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  num_batches=len(train_loader)\n",
        "  train_loss_per_epoch=train_loss/num_batches\n",
        "  print(\"Train Loss:\",train_loss_per_epoch)"
      ],
      "metadata": {
        "id": "znCJWC7khMvu"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Function and Loop\n",
        "def test(test_loader,model,loss_function):\n",
        "  model.eval()\n",
        "  test_loss=0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for features, labels in test_loader:\n",
        "      features, labels = features.to(device), labels.to(device)\n",
        "      predictions=model(features)\n",
        "      loss=loss_function(predictions,labels)\n",
        "      test_loss+=loss.item()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    num_batches=len(test_loader)\n",
        "    test_loss_per_epoch=test_loss/num_batches\n",
        "    print(\"Test Loss:\",test_loss_per_epoch)"
      ],
      "metadata": {
        "id": "Tbgy2PisjGpV"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Function\n",
        "for epoch in range(100):\n",
        "  print(\"epoch: \",epoch)\n",
        "  train(train_loader,model,loss_function,optimizer)\n",
        "  test(test_loader,model,loss_function)\n",
        "  print(\"---------------------------------------------------------------\")\n",
        "  print(\"---------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "jysHzuHij1XU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "3fe23ebe-0922-4795-f706-0d9ec5494f8d"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n",
            "128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-117-55f01afdc0b0>:63: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x=F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n",
            "128\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-b3952d67b3eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-060317110f60>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Like Style for Training Loss and Accuracy"
      ],
      "metadata": {
        "id": "HLaCLraMoVoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Epoch {epoch+1}/{num_epochs} - Batch {batch_idx+1}/{len(dataloader)} - Loss: {loss.item()}\\r\", end='')"
      ],
      "metadata": {
        "id": "vuEjD4p7mOTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for i in range(10):\n",
        "  print(f\"{i}\",end='')\n",
        "  time.sleep(0.7)\n",
        "  print(\"\\r\",end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgOlDkNjmQVG",
        "outputId": "b201cfdf-13b0-4b1e-c9d0-e1a5e18975bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model"
      ],
      "metadata": {
        "id": "h5NcGuWGvLKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model.pt')"
      ],
      "metadata": {
        "id": "MGt3MK2jvNCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model"
      ],
      "metadata": {
        "id": "6MjNN_C-_dUj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUP2aoWN_fzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DUMPSTER\n"
      ],
      "metadata": {
        "id": "QgpYnR5AMO3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imp Random"
      ],
      "metadata": {
        "id": "Gtt1K9VWKVcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # def forward(self,x):\n",
        "    #   xb=xb.reshape(-1,784)\n",
        "    #   out=self.linear(xb)\n",
        "    #   return out\n",
        "\n",
        "    # def training_step(self,batch):\n",
        "    #   images,labels=batch\n",
        "    #   outputs=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   return loss\n",
        "\n",
        "    # def validation_step(self,batch):\n",
        "    #   images, labels=batch\n",
        "    #   out=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   acc=accuracy(outputs,labels)\n",
        "    #   return {'val_loss':loss,'val_acc':acc}\n",
        "\n",
        "\n",
        "# for parameter in model.parameters():\n",
        "# print(parameter.shape\n",
        "# model.linear1\n",
        "# model.linear2\n",
        "# model.activation\n",
        "# model.softmax\n"
      ],
      "metadata": {
        "id": "VSeicov0I7oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.linear1"
      ],
      "metadata": {
        "id": "_WSjvHwEHmat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[1,2,3,4,5,6,7,8,9,10]\n",
        "x_square=[sample**2 for sample in x]\n",
        "x_square"
      ],
      "metadata": {
        "id": "bbUjbeD4qcVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "def evaluate(model,val_loader):\n",
        "  outputs=[models.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "UoAdadqtpXHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Val, Test Loop\n",
        "for epoch in range(100):\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Ac0egWHXfux9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Practices"
      ],
      "metadata": {
        "id": "X9HlgRzfGk4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=O2wJ3tkc-TU\n",
        "# https://www.youtube.com/watch?v=2AhiHV7QGVk"
      ],
      "metadata": {
        "id": "HMEkLd_wGofC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning and HyperParameter Training"
      ],
      "metadata": {
        "id": "GUUx0X1UDP6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=qaDe0qQZ5AQ"
      ],
      "metadata": {
        "id": "ZfF1NTTCDPoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(image).item()"
      ],
      "metadata": {
        "id": "h0LdMB2D4SYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Activation Function, Loss Function, Optimzer:"
      ],
      "metadata": {
        "id": "xqu7G5ITCD-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Optimizer:\n",
        "# https://www.youtube.com/watch?v=zvp8K4iX2Cs&pp=ygUUY3VzdG9tIG1vZGVsIHB5dG9yY2g%3D"
      ],
      "metadata": {
        "id": "nfGfYIoJAS7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk []\n",
        "# https://www.youtube.com/watch?v=OIenNRt2bjg []\n",
        "# https://www.youtube.com/watch?v=H69j69FFMV0 [Dataset Spli First, then Data Loader]\n",
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk"
      ],
      "metadata": {
        "id": "PGAZvl4nGMY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self): #Initializing the MyModel Class\n",
        "    super().__init__() #Calling The Parent Class\n"
      ],
      "metadata": {
        "id": "tWrI3rZxkaFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Dumpster"
      ],
      "metadata": {
        "id": "nZxHW-15M126"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.tensor([1,2,3,4,5])\n",
        "print(data)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "6ZDEw6IqAyWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor Gradients\n",
        "x=torch.tensor(3.)\n",
        "w=torch.tensor(4.,requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True)"
      ],
      "metadata": {
        "id": "TQLDc9scBxw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the value of y\n",
        "y=x*w+b\n",
        "y"
      ],
      "metadata": {
        "id": "fzcRkKifCOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.full((3,3),101)\n",
        "data"
      ],
      "metadata": {
        "id": "OMGdlZ8QDTRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converts numpy array to tensor\n",
        "import numpy as np\n",
        "x=np.ones((3,2))\n",
        "y=torch.from_numpy(x)\n",
        "x.dtype, y.dtype\n",
        "# Internally both are the same"
      ],
      "metadata": {
        "id": "Soe9NU87E3Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Tensor to numpy\n",
        "x=torch.ones((3,2))\n",
        "y=x.numpy()\n",
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "id": "YOznszjsFNsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of element in a tensor\n",
        "x.numel()"
      ],
      "metadata": {
        "id": "NBNt8DIoJceo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if gradient +ve:\n",
        "#   increasing the weight value increases loss\n",
        "#   decreasing the weight value decreases loss\n",
        "\n",
        "# if gradient -ve:\n",
        "#   increasing the weight value decreases loss\n",
        "#   decreasing the weight value increases loss"
      ],
      "metadata": {
        "id": "0b1GFoafCqTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value=value-stepsize\n",
        "value=value-lr*slope\n",
        "value=value-lr*gradient\n",
        "value=value-lr*derivative"
      ],
      "metadata": {
        "id": "htkm5zgMDyH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "loss_func=F.mse_loss\n",
        "loss=loss_func(model(input),labels)"
      ],
      "metadata": {
        "id": "Et0a1zaQPhvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers perform the gradient descent, that is they adjust the weights and biases of parameters\n",
        "optim=torch.optim.SGD(model.parameters,lr=1e-5)"
      ],
      "metadata": {
        "id": "UgnPnhWxSox2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def fit(num_epochs,model,loss_func,optim,train):\n",
        "for epoch in range(num_epochs):\n",
        "  for x,y in train:\n",
        "    prediction=model(x)\n",
        "    loss=loss_func(prediction,y)\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer performs gradient descent and updates the Weights and Biases of Features/Parameters\n",
        "    optim.step()\n",
        "\n",
        "    # Reset the gradients for next epoch\n",
        "    optim.zero_grad()"
      ],
      "metadata": {
        "id": "8M25LGBgSbyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "uOwh4_fIXCMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms are used for handling image data one such usage is ToTensor() function"
      ],
      "metadata": {
        "id": "KO0-5LPoYd-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random split in Pytorch\n",
        "from torch.utils.data import random_split\n",
        "train_ds, val_ds - random_split(dataset, [50000, 10000])\n",
        "len (train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "xBCk0aqjZsUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_data,batch_size,shuffle=True) #Shuffle=True so that with each epoch the batches are not send in the same order, this helps to generalize model better\n",
        "val_loader=DataLoader(val_data,batch_size)"
      ],
      "metadata": {
        "id": "qtDe5F3IaiPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "images.reshape(128,784)\n",
        "model.parameters()\n",
        "model.linear.weights.shape\n",
        "model.linear.bias.shape"
      ],
      "metadata": {
        "id": "p_o82WFvbj8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "numbers = np.arange(1, 21)\n",
        "labels = np.random.randint(0, 2, size=20)\n",
        "df = pd.DataFrame({'Numbers': numbers, 'Labels': labels})\n",
        "df"
      ],
      "metadata": {
        "id": "qKGMpG2ri1Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1:]"
      ],
      "metadata": {
        "id": "ZnORWEf65iLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}