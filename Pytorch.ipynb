{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B3o7FS8UMI-p",
        "KYQssL1p4qjJ",
        "fZu2iEFJo9y4",
        "HLaCLraMoVoa",
        "h5NcGuWGvLKB",
        "6MjNN_C-_dUj",
        "QgpYnR5AMO3n",
        "Gtt1K9VWKVcr",
        "X9HlgRzfGk4u",
        "GUUx0X1UDP6-",
        "xqu7G5ITCD-7",
        "nZxHW-15M126"
      ],
      "authorship_tag": "ABX9TyPgLl2jNCPzCs+cLoqGklHw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Pytorch/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlSBzKQekHBL",
        "outputId": "4c3197d2-4ab8-4042-878c-aa6f57dfe244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k4nLdvWzUVOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Device"
      ],
      "metadata": {
        "id": "B3o7FS8UMI-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "9HwpVdzCGFc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "-NvRrtYVV7Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "9r7TYDYPV_OO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(root='/content/data', train=True, download=True, transform=ToTensor())\n",
        "test_dataset = MNIST(root='/content/data', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "id": "PP2vmyzRWrEg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting features and labels for Training Data\n",
        "X_train=train_dataset.data\n",
        "y_train=train_dataset.targets\n",
        "\n",
        "# Extracting features and labels for Test Data\n",
        "X_test=test_dataset.data\n",
        "y_test=test_dataset.targets"
      ],
      "metadata": {
        "id": "UJ1FVl2_WyRw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZXST_Q3340p",
        "outputId": "4d1a597d-a5f3-4693-c8f4-9879394380e5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Valid Split"
      ],
      "metadata": {
        "id": "KYQssL1p4qjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttv_split(data,train_split,test_split,seed=None):\n",
        "  if train_split+test_split>100:\n",
        "    raise Exception(\"Train, Test Split Should not sum to more than 100%\")\n",
        "  train, test, val  = np.split(data.sample(frac=1,random_state=seed), [int((train_split/100)*len(data)), int(((train_split/100)+(test_split/100))*len(data))])\n",
        "  return train, test, val\n",
        "\n",
        "def train_test_valid_split(features,labels,seed,train_split,test_split):\n",
        "  X_train, X_test, X_val=ttv_split(data=features,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  y_train, y_test, y_val=ttv_split(data=labels,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  return (X_train,y_train),(X_test,y_test),(X_val,y_val)"
      ],
      "metadata": {
        "id": "At784OsbqUTZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test),(X_val,y_val)=train_test_valid_split(features=X,\n",
        "                                                                       labels=y,\n",
        "                                                                       seed=40,\n",
        "                                                                       train_split=60,\n",
        "                                                                       test_split=20)\n",
        "X_train"
      ],
      "metadata": {
        "id": "H-zPGrg3jnAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Dataset and DataLoader"
      ],
      "metadata": {
        "id": "aUkZxlSxMMRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "def MyDataset(features,labels,transform=None):\n",
        "  def __init__(self):\n",
        "    # self.dataset=dataset\n",
        "    self.features=self.dataset.drop(-1)\n",
        "    self.labels=self.dataset\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "    y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
        "    return (image,y_label)\n",
        "# train_loader=DataLoader(dataset=dataset,batch_size=16,shuffle=True,num_worker=4,pin_memory=False)"
      ],
      "metadata": {
        "id": "rXycNwmg6DpF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=MyDataset(X_train,y_train)\n",
        "test_set=MyDataset(X_test,y_test)\n",
        "val_set=MyDataset(X_val,y_val)"
      ],
      "metadata": {
        "id": "NtIoyGD_OMMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "train_loader=DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "test_loader=DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
        "# val_loader=DataLoader(val_set, batch_size=128,shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "J8yinvOM45rX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Model"
      ],
      "metadata": {
        "id": "mx9yC9iqORKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.linear1=torch.nn.Linear(100,200)\n",
        "    self.activation=torch.nn.ReLU()\n",
        "    self.linear2=torch.nn.Linear(200,10)\n",
        "    self.softmax=torch.nn.Softmax()\n",
        "\n",
        "    def forward(self,x):\n",
        "      x=self.linear1(x)\n",
        "      x=self.activation(x)\n",
        "      x=self.linear2(x)\n",
        "      x=self.softmax(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "8IhvIK3gpWkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=train_dataset[0]\n",
        "x.reshape(-1,784).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgKQbDRoPPT1",
        "outputId": "cd549f91-e1ae-4b03-fd86-a0376a9d4158"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=MyModel()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "mmrjvZPdKCOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, Training and testing Loop Setup\n",
        "import torch.nn.functional as F\n",
        "epochs=100\n",
        "learning_rate=1e-4\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "yQA8f7fHK1f6"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class Net(nn.Module):\n",
        "    ''' Models a simple Convolutional Neural Network'''\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\t# Max pooling over a (2, 2) window\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120)# 5x5 from image dimension\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = x.view(-1, 16 * 5 * 5)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERXQoTbX7eTc",
        "outputId": "de5ade68-1b25-4db1-b915-3af720a327c2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Testing and Fit Loops and Functions"
      ],
      "metadata": {
        "id": "fZu2iEFJo9y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function and Loop\n",
        "def train(train_loader,model,loss_function,optimizer):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "    train_loss+=loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  num_batches=len(train_loader)\n",
        "  train_loss_per_epoch=train_loss/num_batches\n",
        "  print(\"Train Loss:\",train_loss_per_epoch)"
      ],
      "metadata": {
        "id": "znCJWC7khMvu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Function and Loop\n",
        "def test(test_loader,model,loss_function):\n",
        "  model.eval()\n",
        "  test_loss=0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for features, labels in test_loader:\n",
        "      features, labels = features.to(device), labels.to(device)\n",
        "      predictions=model(features)\n",
        "      loss=loss_function(predictions,labels)\n",
        "      test_loss+=loss.item()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    num_batches=len(test_loader)\n",
        "    test_loss_per_epoch=test_loss/num_batches\n",
        "    print(\"Test Loss:\",test_loss_per_epoch)"
      ],
      "metadata": {
        "id": "Tbgy2PisjGpV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Function\n",
        "for epoch in range(100):\n",
        "  print(\"epoch: \",epoch)\n",
        "  train(train_loader,model,loss_function,optimizer)\n",
        "  test(test_loader,model,loss_function)"
      ],
      "metadata": {
        "id": "jysHzuHij1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Like Style for Training Loss and Accuracy"
      ],
      "metadata": {
        "id": "HLaCLraMoVoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Epoch {epoch+1}/{num_epochs} - Batch {batch_idx+1}/{len(dataloader)} - Loss: {loss.item()}\\r\", end='')"
      ],
      "metadata": {
        "id": "vuEjD4p7mOTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for i in range(10):\n",
        "  print(f\"{i}\",end='')\n",
        "  time.sleep(0.7)\n",
        "  print(\"\\r\",end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgOlDkNjmQVG",
        "outputId": "b201cfdf-13b0-4b1e-c9d0-e1a5e18975bf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model"
      ],
      "metadata": {
        "id": "h5NcGuWGvLKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model.pt')"
      ],
      "metadata": {
        "id": "MGt3MK2jvNCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model"
      ],
      "metadata": {
        "id": "6MjNN_C-_dUj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUP2aoWN_fzc"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DUMPSTER\n"
      ],
      "metadata": {
        "id": "QgpYnR5AMO3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imp Random"
      ],
      "metadata": {
        "id": "Gtt1K9VWKVcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # def forward(self,x):\n",
        "    #   xb=xb.reshape(-1,784)\n",
        "    #   out=self.linear(xb)\n",
        "    #   return out\n",
        "\n",
        "    # def training_step(self,batch):\n",
        "    #   images,labels=batch\n",
        "    #   outputs=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   return loss\n",
        "\n",
        "    # def validation_step(self,batch):\n",
        "    #   images, labels=batch\n",
        "    #   out=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   acc=accuracy(outputs,labels)\n",
        "    #   return {'val_loss':loss,'val_acc':acc}\n",
        "\n",
        "\n",
        "# for parameter in model.parameters():\n",
        "# print(parameter.shape\n",
        "# model.linear1\n",
        "# model.linear2\n",
        "# model.activation\n",
        "# model.softmax\n"
      ],
      "metadata": {
        "id": "VSeicov0I7oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.linear1"
      ],
      "metadata": {
        "id": "_WSjvHwEHmat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[1,2,3,4,5,6,7,8,9,10]\n",
        "x_square=[sample**2 for sample in x]\n",
        "x_square"
      ],
      "metadata": {
        "id": "bbUjbeD4qcVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "def evaluate(model,val_loader):\n",
        "  outputs=[models.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "UoAdadqtpXHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Val, Test Loop\n",
        "for epoch in range(100):\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Ac0egWHXfux9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Practices"
      ],
      "metadata": {
        "id": "X9HlgRzfGk4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=O2wJ3tkc-TU\n",
        "# https://www.youtube.com/watch?v=2AhiHV7QGVk"
      ],
      "metadata": {
        "id": "HMEkLd_wGofC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning and HyperParameter Training"
      ],
      "metadata": {
        "id": "GUUx0X1UDP6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=qaDe0qQZ5AQ"
      ],
      "metadata": {
        "id": "ZfF1NTTCDPoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(image).item()"
      ],
      "metadata": {
        "id": "h0LdMB2D4SYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Activation Function, Loss Function, Optimzer:"
      ],
      "metadata": {
        "id": "xqu7G5ITCD-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Optimizer:\n",
        "# https://www.youtube.com/watch?v=zvp8K4iX2Cs&pp=ygUUY3VzdG9tIG1vZGVsIHB5dG9yY2g%3D"
      ],
      "metadata": {
        "id": "nfGfYIoJAS7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk []\n",
        "# https://www.youtube.com/watch?v=OIenNRt2bjg []\n",
        "# https://www.youtube.com/watch?v=H69j69FFMV0 [Dataset Spli First, then Data Loader]\n",
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk"
      ],
      "metadata": {
        "id": "PGAZvl4nGMY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self): #Initializing the MyModel Class\n",
        "    super().__init__() #Calling The Parent Class\n"
      ],
      "metadata": {
        "id": "tWrI3rZxkaFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Dumpster"
      ],
      "metadata": {
        "id": "nZxHW-15M126"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.tensor([1,2,3,4,5])\n",
        "print(data)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "6ZDEw6IqAyWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor Gradients\n",
        "x=torch.tensor(3.)\n",
        "w=torch.tensor(4.,requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True)"
      ],
      "metadata": {
        "id": "TQLDc9scBxw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the value of y\n",
        "y=x*w+b\n",
        "y"
      ],
      "metadata": {
        "id": "fzcRkKifCOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.full((3,3),101)\n",
        "data"
      ],
      "metadata": {
        "id": "OMGdlZ8QDTRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converts numpy array to tensor\n",
        "import numpy as np\n",
        "x=np.ones((3,2))\n",
        "y=torch.from_numpy(x)\n",
        "x.dtype, y.dtype\n",
        "# Internally both are the same"
      ],
      "metadata": {
        "id": "Soe9NU87E3Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Tensor to numpy\n",
        "x=torch.ones((3,2))\n",
        "y=x.numpy()\n",
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "id": "YOznszjsFNsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of element in a tensor\n",
        "x.numel()"
      ],
      "metadata": {
        "id": "NBNt8DIoJceo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if gradient +ve:\n",
        "#   increasing the weight value increases loss\n",
        "#   decreasing the weight value decreases loss\n",
        "\n",
        "# if gradient -ve:\n",
        "#   increasing the weight value decreases loss\n",
        "#   decreasing the weight value increases loss"
      ],
      "metadata": {
        "id": "0b1GFoafCqTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value=value-stepsize\n",
        "value=value-lr*slope\n",
        "value=value-lr*gradient\n",
        "value=value-lr*derivative"
      ],
      "metadata": {
        "id": "htkm5zgMDyH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "loss_func=F.mse_loss\n",
        "loss=loss_func(model(input),labels)"
      ],
      "metadata": {
        "id": "Et0a1zaQPhvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers perform the gradient descent, that is they adjust the weights and biases of parameters\n",
        "optim=torch.optim.SGD(model.parameters,lr=1e-5)"
      ],
      "metadata": {
        "id": "UgnPnhWxSox2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def fit(num_epochs,model,loss_func,optim,train):\n",
        "for epoch in range(num_epochs):\n",
        "  for x,y in train:\n",
        "    prediction=model(x)\n",
        "    loss=loss_func(prediction,y)\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer performs gradient descent and updates the Weights and Biases of Features/Parameters\n",
        "    optim.step()\n",
        "\n",
        "    # Reset the gradients for next epoch\n",
        "    optim.zero_grad()"
      ],
      "metadata": {
        "id": "8M25LGBgSbyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "uOwh4_fIXCMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms are used for handling image data one such usage is ToTensor() function"
      ],
      "metadata": {
        "id": "KO0-5LPoYd-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random split in Pytorch\n",
        "from torch.utils.data import random_split\n",
        "train_ds, val_ds - random_split(dataset, [50000, 10000])\n",
        "len (train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "xBCk0aqjZsUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_data,batch_size,shuffle=True) #Shuffle=True so that with each epoch the batches are not send in the same order, this helps to generalize model better\n",
        "val_loader=DataLoader(val_data,batch_size)"
      ],
      "metadata": {
        "id": "qtDe5F3IaiPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "images.reshape(128,784)\n",
        "model.parameters()\n",
        "model.linear.weights.shape\n",
        "model.linear.bias.shape"
      ],
      "metadata": {
        "id": "p_o82WFvbj8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "numbers = np.arange(1, 21)\n",
        "labels = np.random.randint(0, 2, size=20)\n",
        "df = pd.DataFrame({'Numbers': numbers, 'Labels': labels})\n",
        "df"
      ],
      "metadata": {
        "id": "qKGMpG2ri1Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1:]"
      ],
      "metadata": {
        "id": "ZnORWEf65iLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}