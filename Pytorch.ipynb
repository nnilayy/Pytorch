{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B3o7FS8UMI-p",
        "KYQssL1p4qjJ",
        "aUkZxlSxMMRL",
        "cVCbVGWyc6Zz",
        "fZu2iEFJo9y4",
        "HLaCLraMoVoa",
        "h5NcGuWGvLKB",
        "6MjNN_C-_dUj",
        "QgpYnR5AMO3n",
        "Gtt1K9VWKVcr",
        "X9HlgRzfGk4u",
        "GUUx0X1UDP6-",
        "xqu7G5ITCD-7",
        "nZxHW-15M126"
      ],
      "authorship_tag": "ABX9TyNH1lNwccUjRY/f+n5fXMSn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Pytorch/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlSBzKQekHBL",
        "outputId": "32c03a40-b84b-4425-ca42-585b7ab8644c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k4nLdvWzUVOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770d78a2-4598-4e91-9af9-b5e734d24d5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Device"
      ],
      "metadata": {
        "id": "B3o7FS8UMI-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "9HwpVdzCGFc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177929d0-7477-4ddd-e730-180c7b7f1e4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "-NvRrtYVV7Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "9r7TYDYPV_OO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(root='/content/data', train=True, download=True, transform=ToTensor())\n",
        "test_dataset = MNIST(root='/content/data', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "id": "PP2vmyzRWrEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting features and labels for Training Data\n",
        "X_train=train_dataset.data\n",
        "y_train=train_dataset.targets\n",
        "\n",
        "# Extracting features and labels for Test Data\n",
        "X_test=test_dataset.data\n",
        "y_test=test_dataset.targets"
      ],
      "metadata": {
        "id": "UJ1FVl2_WyRw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZXST_Q3340p",
        "outputId": "cdaeac9f-db72-47c7-83a8-944f4871fa34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Valid Split"
      ],
      "metadata": {
        "id": "KYQssL1p4qjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ttv_split(data,train_split,test_split,seed=None):\n",
        "  if train_split+test_split>100:\n",
        "    raise Exception(\"Train, Test Split Should not sum to more than 100%\")\n",
        "  train, test, val  = np.split(data.sample(frac=1,random_state=seed), [int((train_split/100)*len(data)), int(((train_split/100)+(test_split/100))*len(data))])\n",
        "  return train, test, val\n",
        "\n",
        "def train_test_valid_split(features,labels,seed,train_split,test_split):\n",
        "  X_train, X_test, X_val=ttv_split(data=features,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  y_train, y_test, y_val=ttv_split(data=labels,seed=seed,train_split=train_split,test_split=test_split)\n",
        "  return (X_train,y_train),(X_test,y_test),(X_val,y_val)"
      ],
      "metadata": {
        "id": "At784OsbqUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test),(X_val,y_val)=train_test_valid_split(features=X,\n",
        "                                                                       labels=y,\n",
        "                                                                       seed=40,\n",
        "                                                                       train_split=60,\n",
        "                                                                       test_split=20)\n",
        "X_train"
      ],
      "metadata": {
        "id": "H-zPGrg3jnAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Dataset"
      ],
      "metadata": {
        "id": "aUkZxlSxMMRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "def MyDataset(features,labels,transform=None):\n",
        "  def __init__(self):\n",
        "    # self.dataset=dataset\n",
        "    self.features=self.dataset.drop(-1)\n",
        "    self.labels=self.dataset\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "    y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
        "    return (image,y_label)\n",
        "# train_loader=DataLoader(dataset=dataset,batch_size=16,shuffle=True,num_worker=4,pin_memory=False)"
      ],
      "metadata": {
        "id": "rXycNwmg6DpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=MyDataset(X_train,y_train)\n",
        "test_set=MyDataset(X_test,y_test)\n",
        "val_set=MyDataset(X_val,y_val)"
      ],
      "metadata": {
        "id": "NtIoyGD_OMMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "cVCbVGWyc6Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "test_loader=DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
        "# val_loader=DataLoader(val_set, batch_size=128,shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "J8yinvOM45rX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Model"
      ],
      "metadata": {
        "id": "mx9yC9iqORKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1=torch.nn.Conv2d(1,32,kernel_size=3,padding=1)\n",
        "    self.conv2=torch.nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool1=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv3=torch.nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "    self.conv4=torch.nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool2=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    self.conv5=torch.nn.Conv2d(128,256,kernel_size=3,padding=1)\n",
        "    self.conv6=torch.nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1)\n",
        "    self.maxpool3=torch.nn.MaxPool2d(2,2)\n",
        "\n",
        "    # self.flatten=torch.nn.Flatten()\n",
        "    self.fc1=torch.nn.Linear(256*4*4,1024)\n",
        "    self.fc2=torch.nn.Linear(1024,512)\n",
        "    self.fc32=torch.nn.Linear(512,10)\n",
        "\n",
        "    # self.softmax=torch.nn.Softmax()\n",
        "    # self.relu3=torch.nn.ReLU()\n",
        "    # self.relu4=torch.nn.ReLU()\n",
        "    # self.relu5=torch.nn.ReLU()\n",
        "    # self.relu6=torch.nn.ReLU()\n",
        "    # self.relu7=torch.nn.ReLU()\n",
        "    # self.relu8=torch.nn.ReLU()\n",
        "    # self.relu1=torch.nn.ReLU()\n",
        "    # self.relu2=torch.nn.ReLU()\n",
        "    # self.conv2=torch.nn.Linear(100,200)\n",
        "    # self.maxpool2=torch.nn.Linear(100,200)\n",
        "    # self.relu2=torch.torch.nn.ReLU()\n",
        "    # self.softmax=torch.nn.Softmax()\n",
        "    # self.linear2=torch.nn.Linear(200,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.maxpool1(x)\n",
        "\n",
        "    x=self.conv3(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv4(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.maxpool2(x)\n",
        "\n",
        "    x=self.conv5(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.conv6(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.maxpool3(x)\n",
        "\n",
        "    x=x.view(-1,)\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    x=F.relu(x)\n",
        "    x=F.log_softmax(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "8IhvIK3gpWkR"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=train_dataset[0]\n",
        "x.reshape(-1,784).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgKQbDRoPPT1",
        "outputId": "cd549f91-e1ae-4b03-fd86-a0376a9d4158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "model=MyModel()\n",
        "model.to(device)\n",
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "id": "mmrjvZPdKCOS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "c5dcaea2-cf02-4740-bdf3-50ba5e9f25fb"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-604f276af309>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-e0cf82cbe699>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 4096]' is invalid for input of size 4608"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "C2j8V4A1tTyX",
        "outputId": "debbb80b-e6d8-4553-9a26-df7709bf95a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-73dbd4d02c6d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-425a1afcb717>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             for hook_id, hook in (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 3, 3, 3], expected input[2, 1, 28, 28] to have 3 channels, but got 1 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, Training and testing Loop Setup\n",
        "import torch.nn.functional as F\n",
        "epochs=100\n",
        "learning_rate=1e-4\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "yQA8f7fHK1f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class Net(nn.Module):\n",
        "    ''' Models a simple Convolutional Neural Network'''\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\t# Max pooling over a (2, 2) window\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120)# 5x5 from image dimension\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = x.view(-1, 16 * 5 * 5)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n"
      ],
      "metadata": {
        "id": "ERXQoTbX7eTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.full((28,28),100)\n",
        "x=x.view(-1,784)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4-Z3aY2mv4x",
        "outputId": "bce27a08-9780-4409-d5c4-8c52a5b38ce5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Testing and Fit Loops and Functions"
      ],
      "metadata": {
        "id": "fZu2iEFJo9y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function and Loop\n",
        "def train(train_loader,model,loss_function,optimizer):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "    train_loss+=loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  num_batches=len(train_loader)\n",
        "  train_loss_per_epoch=train_loss/num_batches\n",
        "  print(\"Train Loss:\",train_loss_per_epoch)"
      ],
      "metadata": {
        "id": "znCJWC7khMvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Function and Loop\n",
        "def test(test_loader,model,loss_function):\n",
        "  model.eval()\n",
        "  test_loss=0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for features, labels in test_loader:\n",
        "      features, labels = features.to(device), labels.to(device)\n",
        "      predictions=model(features)\n",
        "      loss=loss_function(predictions,labels)\n",
        "      test_loss+=loss.item()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    num_batches=len(test_loader)\n",
        "    test_loss_per_epoch=test_loss/num_batches\n",
        "    print(\"Test Loss:\",test_loss_per_epoch)"
      ],
      "metadata": {
        "id": "Tbgy2PisjGpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Function\n",
        "for epoch in range(100):\n",
        "  print(\"epoch: \",epoch)\n",
        "  train(train_loader,model,loss_function,optimizer)\n",
        "  test(test_loader,model,loss_function)"
      ],
      "metadata": {
        "id": "jysHzuHij1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Like Style for Training Loss and Accuracy"
      ],
      "metadata": {
        "id": "HLaCLraMoVoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Epoch {epoch+1}/{num_epochs} - Batch {batch_idx+1}/{len(dataloader)} - Loss: {loss.item()}\\r\", end='')"
      ],
      "metadata": {
        "id": "vuEjD4p7mOTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for i in range(10):\n",
        "  print(f\"{i}\",end='')\n",
        "  time.sleep(0.7)\n",
        "  print(\"\\r\",end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgOlDkNjmQVG",
        "outputId": "b201cfdf-13b0-4b1e-c9d0-e1a5e18975bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Model"
      ],
      "metadata": {
        "id": "h5NcGuWGvLKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model.pt')"
      ],
      "metadata": {
        "id": "MGt3MK2jvNCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model"
      ],
      "metadata": {
        "id": "6MjNN_C-_dUj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUP2aoWN_fzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DUMPSTER\n"
      ],
      "metadata": {
        "id": "QgpYnR5AMO3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imp Random"
      ],
      "metadata": {
        "id": "Gtt1K9VWKVcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # def forward(self,x):\n",
        "    #   xb=xb.reshape(-1,784)\n",
        "    #   out=self.linear(xb)\n",
        "    #   return out\n",
        "\n",
        "    # def training_step(self,batch):\n",
        "    #   images,labels=batch\n",
        "    #   outputs=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   return loss\n",
        "\n",
        "    # def validation_step(self,batch):\n",
        "    #   images, labels=batch\n",
        "    #   out=self(images)\n",
        "    #   loss=F.cross_entropy(outputs,labels)\n",
        "    #   acc=accuracy(outputs,labels)\n",
        "    #   return {'val_loss':loss,'val_acc':acc}\n",
        "\n",
        "\n",
        "# for parameter in model.parameters():\n",
        "# print(parameter.shape\n",
        "# model.linear1\n",
        "# model.linear2\n",
        "# model.activation\n",
        "# model.softmax\n"
      ],
      "metadata": {
        "id": "VSeicov0I7oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.linear1"
      ],
      "metadata": {
        "id": "_WSjvHwEHmat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[1,2,3,4,5,6,7,8,9,10]\n",
        "x_square=[sample**2 for sample in x]\n",
        "x_square"
      ],
      "metadata": {
        "id": "bbUjbeD4qcVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "def evaluate(model,val_loader):\n",
        "  outputs=[models.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "UoAdadqtpXHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Val, Test Loop\n",
        "for epoch in range(100):\n",
        "  for features, labels in train_loader:\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    predictions=model(features)\n",
        "    loss=loss_function(predictions,labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Ac0egWHXfux9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Practices"
      ],
      "metadata": {
        "id": "X9HlgRzfGk4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=O2wJ3tkc-TU\n",
        "# https://www.youtube.com/watch?v=2AhiHV7QGVk"
      ],
      "metadata": {
        "id": "HMEkLd_wGofC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning and HyperParameter Training"
      ],
      "metadata": {
        "id": "GUUx0X1UDP6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=qaDe0qQZ5AQ"
      ],
      "metadata": {
        "id": "ZfF1NTTCDPoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(image).item()"
      ],
      "metadata": {
        "id": "h0LdMB2D4SYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Activation Function, Loss Function, Optimzer:"
      ],
      "metadata": {
        "id": "xqu7G5ITCD-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Optimizer:\n",
        "# https://www.youtube.com/watch?v=zvp8K4iX2Cs&pp=ygUUY3VzdG9tIG1vZGVsIHB5dG9yY2g%3D"
      ],
      "metadata": {
        "id": "nfGfYIoJAS7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk []\n",
        "# https://www.youtube.com/watch?v=OIenNRt2bjg []\n",
        "# https://www.youtube.com/watch?v=H69j69FFMV0 [Dataset Spli First, then Data Loader]\n",
        "# https://www.youtube.com/watch?v=SDPeeX6LEnk"
      ],
      "metadata": {
        "id": "PGAZvl4nGMY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self): #Initializing the MyModel Class\n",
        "    super().__init__() #Calling The Parent Class\n"
      ],
      "metadata": {
        "id": "tWrI3rZxkaFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Dumpster"
      ],
      "metadata": {
        "id": "nZxHW-15M126"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.tensor([1,2,3,4,5])\n",
        "print(data)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "6ZDEw6IqAyWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor Gradients\n",
        "x=torch.tensor(3.)\n",
        "w=torch.tensor(4.,requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True)"
      ],
      "metadata": {
        "id": "TQLDc9scBxw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the value of y\n",
        "y=x*w+b\n",
        "y"
      ],
      "metadata": {
        "id": "fzcRkKifCOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=torch.full((3,3),101)\n",
        "data"
      ],
      "metadata": {
        "id": "OMGdlZ8QDTRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converts numpy array to tensor\n",
        "import numpy as np\n",
        "x=np.ones((3,2))\n",
        "y=torch.from_numpy(x)\n",
        "x.dtype, y.dtype\n",
        "# Internally both are the same"
      ],
      "metadata": {
        "id": "Soe9NU87E3Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Tensor to numpy\n",
        "x=torch.ones((3,2))\n",
        "y=x.numpy()\n",
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "id": "YOznszjsFNsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of element in a tensor\n",
        "x.numel()"
      ],
      "metadata": {
        "id": "NBNt8DIoJceo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if gradient +ve:\n",
        "#   increasing the weight value increases loss\n",
        "#   decreasing the weight value decreases loss\n",
        "\n",
        "# if gradient -ve:\n",
        "#   increasing the weight value decreases loss\n",
        "#   decreasing the weight value increases loss"
      ],
      "metadata": {
        "id": "0b1GFoafCqTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value=value-stepsize\n",
        "value=value-lr*slope\n",
        "value=value-lr*gradient\n",
        "value=value-lr*derivative"
      ],
      "metadata": {
        "id": "htkm5zgMDyH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "loss_func=F.mse_loss\n",
        "loss=loss_func(model(input),labels)"
      ],
      "metadata": {
        "id": "Et0a1zaQPhvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers perform the gradient descent, that is they adjust the weights and biases of parameters\n",
        "optim=torch.optim.SGD(model.parameters,lr=1e-5)"
      ],
      "metadata": {
        "id": "UgnPnhWxSox2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def fit(num_epochs,model,loss_func,optim,train):\n",
        "for epoch in range(num_epochs):\n",
        "  for x,y in train:\n",
        "    prediction=model(x)\n",
        "    loss=loss_func(prediction,y)\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer performs gradient descent and updates the Weights and Biases of Features/Parameters\n",
        "    optim.step()\n",
        "\n",
        "    # Reset the gradients for next epoch\n",
        "    optim.zero_grad()"
      ],
      "metadata": {
        "id": "8M25LGBgSbyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "uOwh4_fIXCMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms are used for handling image data one such usage is ToTensor() function"
      ],
      "metadata": {
        "id": "KO0-5LPoYd-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random split in Pytorch\n",
        "from torch.utils.data import random_split\n",
        "train_ds, val_ds - random_split(dataset, [50000, 10000])\n",
        "len (train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "xBCk0aqjZsUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size=128\n",
        "train_loader=DataLoader(train_data,batch_size,shuffle=True) #Shuffle=True so that with each epoch the batches are not send in the same order, this helps to generalize model better\n",
        "val_loader=DataLoader(val_data,batch_size)"
      ],
      "metadata": {
        "id": "qtDe5F3IaiPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "images.reshape(128,784)\n",
        "model.parameters()\n",
        "model.linear.weights.shape\n",
        "model.linear.bias.shape"
      ],
      "metadata": {
        "id": "p_o82WFvbj8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "numbers = np.arange(1, 21)\n",
        "labels = np.random.randint(0, 2, size=20)\n",
        "df = pd.DataFrame({'Numbers': numbers, 'Labels': labels})\n",
        "df"
      ],
      "metadata": {
        "id": "qKGMpG2ri1Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1:]"
      ],
      "metadata": {
        "id": "ZnORWEf65iLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}